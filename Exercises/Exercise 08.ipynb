{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6",
      "name": "python36",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat_minor": 2,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport sklearn.compose as sc\nimport sklearn.preprocessing as sp\nimport sklearn.linear_model as sl\nimport sklearn.metrics as sm\nimport sklearn.pipeline as spipe\nimport sklearn.model_selection as sms\nimport tensorflow.keras.models as km\nimport tensorflow.keras.layers as kl\nimport tensorflow.keras.wrappers.scikit_learn as kw\n\nnp.random.seed(42)\n\nX = np.genfromtxt(\"data/trainX.dat\")\nt = np.genfromtxt(\"data/traint.dat\")\n\n## Bring into data frame for easier wrangling and plotting\ndf = pd.DataFrame(X)\ndf['target'] = t\n\ndf.describe()\n\nqual_cols = (0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18)\nquant_cols = [1, 4, 12, 19]\n\n## Plot data from continuous columns\n#sns.pairplot(df, vars = quant_cols, hue = 'target');\n\ntrans = sc.make_column_transformer( \\\n    (sp.StandardScaler(), \\\n     quant_cols), \\\n    (sp.OneHotEncoder(categories = [np.arange(1, 5)], \\\n                      sparse = False), \\\n     [0]), \\\n    (sp.OneHotEncoder(categories = [np.arange(0, 5)], \\\n                      sparse = False),\n     [2]), \\\n    (sp.OneHotEncoder(categories = [np.arange(0, 11)], \\\n                      sparse = False),\n     [3]), \\\n    (sp.OneHotEncoder(categories = [np.arange(1, 6)], \\\n                      sparse = False),\n     [5]), \\\n    (sp.OneHotEncoder(categories = [np.arange(1, 6)], \\\n                      sparse = False),\n     [6]), \\\n    (sp.OneHotEncoder(categories = [np.arange(1, 5)], \\\n                      sparse = False),\n     [7]), \\\n    (sp.OneHotEncoder(categories = [np.arange(1, 5)], \\\n                      sparse = False),\n     [8]), \\\n    (sp.OneHotEncoder(categories = [np.arange(1, 4)], \\\n                      sparse = False),\n     [9]), \\\n    (sp.OneHotEncoder(categories = [np.arange(1, 5)], \\\n                      sparse = False),\n     [10]), \\\n    (sp.OneHotEncoder(categories = [np.arange(1, 5)], \\\n                      sparse = False),\n     [11]), \\\n    (sp.OneHotEncoder(categories = [np.arange(1, 4)], \\\n                      sparse = False),\n     [13]), \\\n    (sp.OneHotEncoder(categories = [np.arange(1, 4)], \\\n                      sparse = False),\n     [14]), \\\n    (sp.OneHotEncoder(categories = [np.arange(1, 5)], \\\n                      sparse = False),\n     [15]), \\\n    (sp.OneHotEncoder(categories = [np.arange(1, 5)], \\\n                      sparse = False),\n     [16]), \\\n    (sp.OneHotEncoder(categories = [np.arange(1, 3)], \\\n                      sparse = False),\n     [17]), \\\n    (sp.OneHotEncoder(categories = [np.arange(1, 3)], \\\n                      sparse = False),\n     [18]))\n    \nmodel = spipe.Pipeline(steps = [('recode', trans),\n                                ('classify', sl.LogisticRegression(solver = \"liblinear\"))])\n## GridSearch to find regularizer and strength via CV\ngrid = sms.GridSearchCV(model, {'classify__penalty': [\"l1\", \"l2\"], 'classify__C': [1, 10, 100, 1000]}, cv = 10)\n\n## Fit model and predict class probabilities\nfit = grid.fit(X, t)\nprob = fit.predict_proba(X)\nfit.best_params_\n\nprob = fit.predict_proba(X)\npred = prob[:, 0] < 1 / 6.\n\n## Always look at the confusion matrix!\ncm = sm.confusion_matrix(t, pred)\n\ndef loss(cm):\n    return 5. * cm[0, 1] + cm[1, 0]\n\nprint(cm)\nprint(loss(cm))\n\n## get size of transformed data\nN, D = trans.fit_transform(X).shape\n\ndef nn_model():\n    # create model\n    model = km.Sequential()\n    model.add(kl.Dense(100, input_dim=D, activation='relu'))\n    model.add(kl.Dropout(rate = 0.4))\n    model.add(kl.Dense(10, activation='relu'))\n    model.add(kl.Dense(1, activation='sigmoid'))\n    # Compile model\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n\nnn = spipe.Pipeline(steps = [('preprocess', trans),\n                             ('net', kw.KerasClassifier(build_fn = nn_model,\n                                                        epochs=30, batch_size=32, verbose=1))])\nnn_fit = nn.fit(X, t)\n\nnn_prob = nn.predict_proba(X)\n\nnn_pred = nn_prob[:, 0] < 1 / 6.\nnn_cm = sm.confusion_matrix(t, nn_pred)\n\nprint(nn_cm)\nprint(loss(nn_cm))\n\nX_test = np.genfromtxt(\"data/testX.dat\")\nt_test = np.genfromtxt(\"data/testt.dat\")\n\nnn_pred_test = nn.predict_proba(X_test)[:, 0] < 1 / 6.\nnn_cm_test = sm.confusion_matrix(t_test, nn_pred_test)\n\nprint(nn_cm_test)\nprint(loss(nn_cm_test))",
      "metadata": {
        "collapsed": true,
        "trusted": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/matplotlib/font_manager.py:229: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n  'Matplotlib is building the font cache using fc-list. '\n",
          "name": "stderr",
          "output_type": "stream"
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn.compose'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1d4b19783b45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.compose'"
          ],
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}